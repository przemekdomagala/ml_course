# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nnqWlOFggq5TvxD5nLM5FHGW2sTCRiOv
"""

import tensorflow as tf

tf.keras.utils.get_file("bike_sharing_dataset.zip", "https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip", cache_dir=".", extract=True)

import pandas as pd

df = pd.read_csv('datasets/hour.csv',
parse_dates={'datetime': ['dteday', 'hr']},
date_format='%Y-%m-%d %H',
index_col='datetime'
)

print((df.index.min(), df.index.max()))

(365 + 366) * 24 - len(df)

df

df = df.resample('H').asfreq()

# Wypełnianie brakujących danych
df['casual'].fillna(0, inplace=True)
df['registered'].fillna(0, inplace=True)
df['cnt'].fillna(0, inplace=True)

df['temp'].interpolate(inplace=True)
df['atemp'].interpolate(inplace=True)
df['hum'].interpolate(inplace=True)
df['windspeed'].interpolate(inplace=True)

df['holiday'].fillna(method='ffill', inplace=True)
df['weekday'].fillna(method='ffill', inplace=True)
df['workingday'].fillna(method='ffill', inplace=True)
df['weathersit'].fillna(method='ffill', inplace=True)

print(df.notna().sum())

df.casual /= 1e3
df.registered /= 1e3
df.cnt /= 1e3
df.weathersit /= 4

print(df[['casual', 'registered', 'cnt', 'weathersit']].describe())

import pickle

mae_daily = df['cnt'].diff(24).abs().mean() * 1e3
mae_weekly = df['cnt'].diff(24*7).abs().mean() * 1e3
mae_baseline = (mae_daily, mae_weekly)
print(mae_baseline)

with open('mae_baseline.pkl', 'wb') as f:
    pickle.dump(mae_baseline, f)

cnt_train = df['cnt']['2011-01-01 00:00':'2012-06-30 23:00']
cnt_valid = df['cnt']['2012-07-01 00:00':]

seq_len = 24

train_ds = tf.keras.utils.timeseries_dataset_from_array(
    cnt_train.to_numpy(),
    targets=cnt_train[seq_len:],
    sequence_length=seq_len,
    batch_size=32,
    shuffle=True,
    seed=42
)

valid_ds = tf.keras.utils.timeseries_dataset_from_array(
    cnt_valid.to_numpy(),
    targets=cnt_valid[seq_len:],
    sequence_length=seq_len,
    batch_size=32
)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(1, input_shape=[seq_len])
])

model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),
    loss=tf.keras.losses.Huber(),
    metrics=['mae']
)

history = model.fit(train_ds, epochs=20, validation_data=valid_ds)

model.save('model_linear.keras')

mae_linear = model.evaluate(valid_ds, verbose=0)[1] * 1e3

with open('mae_linear.pkl', 'wb') as f:
    pickle.dump((mae_linear,), f)

model = tf.keras.Sequential([
tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])])

model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9),
    loss=tf.keras.losses.Huber(),
    metrics=['mae']
)

history = model.fit(train_ds, epochs=20, validation_data=valid_ds)

model.save('model_rnn1.keras')

mae_linear = model.evaluate(valid_ds, verbose=0)[1] * 1e3

with open('mae_rnn1.pkl', 'wb') as f:
    pickle.dump((mae_linear,), f)

univar_model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),
    tf.keras.layers.Dense(1)
])

univar_model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9),
    loss=tf.keras.losses.Huber(),
    metrics=['mae']
)

history = univar_model.fit(train_ds, epochs=20, validation_data=valid_ds)

univar_model.save('model_rnn32.keras')

mae_linear = univar_model.evaluate(valid_ds, verbose=0)[1] * 1e3

with open('mae_rnn32.pkl', 'wb') as f:
    pickle.dump((mae_linear,), f)

deep_model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),
    tf.keras.layers.SimpleRNN(32, return_sequences=True),
    tf.keras.layers.SimpleRNN(32),
    tf.keras.layers.Dense(1)
])

opt = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.9)
deep_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=["mae"])
history = deep_model.fit(train_ds, epochs=20, validation_data=valid_ds)

deep_model.save('model_rnn_deep.keras')

mae_linear = deep_model.evaluate(valid_ds, verbose=0)[1] * 1e3

with open('mae_rnn_deep', 'wb') as f:
    pickle.dump((mae_linear,), f)

cnt_train = df[['cnt', 'weathersit', 'atemp', 'workingday']]['2011-01-01 00:00':'2012-06-30 23:00']
cnt_valid = df[['cnt', 'weathersit', 'atemp', 'workingday']]['2012-07-01 00:00':]

train_ds = tf.keras.utils.timeseries_dataset_from_array(
    cnt_train.to_numpy(),
    targets=cnt_train[seq_len:],
    sequence_length=seq_len,
    batch_size=32,
    shuffle=True,
    seed=42
)

valid_ds = tf.keras.utils.timeseries_dataset_from_array(
    cnt_valid.to_numpy(),
    targets=cnt_valid[seq_len:],
    sequence_length=seq_len,
    batch_size=32
)

mulvar_model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(32, input_shape=[None, 4]),
    tf.keras.layers.Dense(1)
])

opt = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.9)
mulvar_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=["mae"])
history = mulvar_model.fit(train_ds, epochs=20, validation_data=valid_ds)

mulvar_model.save('model_rnn_mv.keras')

mae_linear = mulvar_model.evaluate(valid_ds, verbose=0)[1] * 1e3

with open('mae_rnn_mv.pkl', 'wb') as f:
    pickle.dump((mae_linear,), f)